#Mysql实战45讲



##启动MySQL

```
# 启动MySQL
mysql.server start
mysql -u root -p 123456

# 查看MySQL版本
mysql -V
或者在mysql 命令行执行
status
```



## 一条SQL语句是如何执行的

mysql 的逻辑架构分为三层：

- 客户端：
- server 层：查询缓存、分析器、优化器、执行器、MySQL常用的函数，存储过程。所有跨存储引擎的过程。
- 存储引擎层：innodb、myisam

```flow
st=>start: 接收客户端请求
res=>operation: 返回数据集
op1=>operation: 词法分析器
op2=>operation: 语法分析器
op3=>operation: 优化器
op4=>operation: 执行器
op5=>operation: 存储引擎

st->op1->op2->op3->op4->op5->res
```

**关于数据库连接，会出现的几个问题：**

显示当前数据库的连接

```
show precesslist;
mysql> show processlist;
```

msyql 长连接和短连接是什么情况，为什么使用长连接？

```
短连接：执行完很少的几次查询之后，断开连接，下次查询重新建立一个新连接。
长连接：连接建立成功后，如果客户端持续请求，则一直使用同一个连接。

建立连接的操作比较复杂，所以通常使用长连接。
```

全部使用长连接带来什么问题?

```
问题1：MySQL 内存涨的快，因为MySQL在执行过程中使用的内存是管理在连接对象里面的，这些资源在断开连接的时候才会释放。所以长连接积累下来，可能导致内存占用太大，被系统强行杀掉，从现象看就是MySQL异常重启。

解决方案：
1、定期断开长连接，使用一段时间或者执行了一个占用内存较大的查询之后，断开重连。
2、MySQL 如果是 5.7 以上的版本，通过执行 mysql_reset_connection 来重新初始化连接，不需要重连和权限校验，连接恢复到初始状态。
```



## 一条SQL语句的更新时如何执行的

数据更新的时候也需要执行词法分析、语法分析、优化、执行等过程。

**redo log & binlog & 区别**

redo log 是 innodb 存储引擎实现的功能

mysql 在更新的过程中用到WAL(wirte-ahead-log)，关键点就是先写日志再写磁盘，等系统空闲时再从日志写到磁盘。

具体：当需要更行一条记录的时候，innodb引擎会把记录先写到 redo log 并更新内存，此时更新完成。引擎会在空闲时将这个操作记录更新到磁盘。

redo log 的大小是固定的，比如可以配置为一组4个文件，每个文件1GB，从头开始写，写完之后再从头开始写。可以理解为一个环形的结构，write pos 标记能够写入的位置，checkpoint 标识需要将redo log 写入到磁盘的位置。两者之间是可用的空间。

redo log 这个机制保证了数据库异常重启之后，之前提交的记录不会消失，这个能力为 crash-safe.

binlog 是MySQL server 层实现的归档日志。



**两种日志之间的不同：**

1. redo log 是 innodb 引擎特有的；binlog 是 MySQL 的 server 层实现的，所有的引擎都可以使用。
2. redo log 是物理日志，记录的是在某个数据页上做了什么修改；binlog 是逻辑日志，记录了这个语句的原始逻辑，比如 "给 ID= 2 这一行的 c 字段 加1"。
3. redo log 是循环写的，binlog 是追加写的。binlog 文件写到一定大小后会切换到下一个，不会覆盖。

**两阶段提交**

S:server 层

D: innodb层

```flow
op1=>operation: S:取ID=2这一行
cond=>condition: D:是否在内存?
op2=>operation: D:返回行数据
op3=>operation: S:将返回的行+1
op4=>operation: S:写入新的行
op5=>operation: D:新行更新到内存
op6=>operation: D:写入relog(prepare阶段)
op7=>operation: S:写入binlog
op8=>operation: D:提交事物(commit 状态)
op9=>operation: D:磁盘中读入内存
op1->cond
cond(yes)->op2
cond(no)->op9->op2
op2->op3->op4->op5->op6->op7->op8

```



**为什么使用两阶段提交**

```
1. 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。

2. 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。
```



## 事物隔离

**事物的ACID**

- 原子性	Atomicity
- 一致性	Consistency
- 隔离性	Isolation
- 持久性	Durablity



**事物的隔离级别**

- 读未提交 - read uncommitted：一个事务未提交时，可被其他事务看到
- 读提交 - read committed：一个事务提交后，才可以被其他事务看到。
- 可重复读 - repeatable read：一个事务在执行中看到的数据，总是和这个事物启动时看到的是一样的。
- 串行化 - serializable：读写都会加锁。

**事物隔离的实现**

回滚日志：每条记录在更新的时候同时会记录一条回滚操作，记录上的最新值 ，通过回滚操作可以得到前一个状态的值。

回滚日志删除：在不需要的时候删除，系统会判断当没有事务在需要这些回滚日志的时候，回滚日志会被删除。当系统里面没有比这个回滚日志更早的read-view的时候，回滚日志就会删除。因为这个原因，长事务会保留很多回滚日志，所以不推荐使用。

MVCC：同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制。

**事务的启动方式**

显示启动事务，begin 或 start transaction。提交 commit，回滚 rollback。

autocommit=1 可以自动提交未显示开启的事务，如select、update



## 索引

**索引常见模型**

哈希表：根据key计算得到hash值，值重复的时候使用链表来存储。所以哈希表这种结构只适用于只有等值查询的场景。比如 memercached 以及一些nosql数据库。

有序数组：在插入新的记录的时候，需要移动其他数组顺序，有序数组索引只适用于静态存储引擎。适用于历史数据类的，不会再变动的数据。

搜索树：innodb引擎使用的就是一种b+树的索引

**innodb 索引**

主键索引：存储的是一个个数据页，在数据页中存储了多条行记录，在 innodb 中主键索引也称为聚簇索引。

非主键索引：内容为主键值，非主键索引也称为二级索引。

**索引维护**

为什么我们需要维护一个自增长的主键id？

```
innodb 的索引的叶子节点存储的是数据页，向中间的数据页插入数据可能引起页分裂、增加新页的过程。同时也会造成页存储的空洞。
当使用自增有序插入的时候，天然符合这种索引结构，每次插入都是一条记录都是追加操作，不涉及记录移动，不涉及叶子节点分裂。
```

**重建索引**

```
# 重建索引 k
alter table T drop index k;
alter table T add index(k);

# 重建主键索引 id
alter table T drop primary key;
alter table T add primary key(id);

# 重建主键索引会引起二级索引的变化，这一点在重建主键索引的时候需要注意。
```

**覆盖索引**

只需要查询二级索引数就可以得到查询结果，不需要回表查询，称之为覆盖索引。

查询字段、where 条件中的字段都必须可以使用二级索引解决。

**最左前缀原则**

之所以会有最左前缀，是因为索引的存储是有序的，联合索引的存储也是有序的。

如果通过顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑的。

**索引下推**

MySQL5.6 引入了索引下推，可以在索引遍历的过程中，对索引中包含的字段先做判断，直接过滤掉不满足的记录，减少回表次数。



## 全局锁、表锁

**全局锁**

对整个数据库实例加锁，可以执行`Flush table with read lock`，之后其他线程的以下语句会被阻塞：

- 数据更新语句 - 增删改
- 数据定义语句 - 建表、修改表结构
- 更新类事物提交语句 

使用场景：做全库逻辑备份。对于innodb场景，可以使用开启一个事物来备份，期间不影响数据库的读写。



**表级锁**

表级锁有两种：

- 表锁
- 元数据锁(meta data lock, MDL)



**表锁语法**

```
lock tables ... read/write

unlock tables
```

举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。



**MDL:**

- 增删查改的时候会加MDL读锁
- 改表结构的时候加MDL写锁
- 读锁之间不互斥
- 读锁写锁互斥，写锁之间互斥，

在更新热点小表的时候，可以使用下面语句：

```
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```



## 行锁

**两阶段锁**

- innodb 事务中，行锁是在需要的时候才加上去的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
- 帮助点：如果事务中需要锁多个行，把最可能冲突、最可能影响并发读的锁尽量往后放



**死锁和死锁检测**

死锁应对策略：

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

对于热点数据的更新引起的死锁问题：

- 1、在确保业务不会出现死锁的时候，可以临时把死锁检测关掉
- 2、控制并发度。
- 3、将热点数据进行变动，例如如果是账户余额记录的时候，可以把记录变动成10行来更新



## 事务到底是隔离还是不隔离的

**快照在MVCC是如何工作的**

事物在启动的时候，会根据事物id获取当前整个数据库的视图。

**数据一致性实现**

- 对于innodb 中的每条记录，存在多个版本，可以根据回滚日志来确定到某一个版本
- 事务在启动的时候，能看到所有已经提交的事物，在这之后事执行期间其他事物的更新对这个事物不可见。
- 实现上，innodb 为每个事物构成一个数组，用来保存在这个事物启动的瞬间，当前已经启动了但是未提交的事物。

可以总结为下面三种情况；

- 版本未提交，不可见；
- 版本已提交，但是是在视图创建后提交的，不可见；
- 版本已提交，而且是在视图创建前提交的，可见。



**更新逻辑**

事物中的读使用的是一致性读

事务中的更新使用的是当前读，读取记录当前最新的值。



## 普通索引和唯一索引，如何选择

**查询过程**

- 普通索引，查找到满足条件的记录之后，会继续查找，知道碰到第一个不满足条件的记录。
- 查找到第一个满足条件的记录后，就会停止。
- 两者在加锁的时候有区别，等值查询的时候，唯一索引的锁会有next-key lock 退化为 行锁。
- 查找性能的差距非常小。

**什么是 change buffer**

- 当需要更新一个数据页时，如果数据页在内存中直接更新，如果内存中不存在的话，在不影响数据一致性的前提下，innodb 会将这些更新操作缓存到 change buffer中，这样就不需要从磁盘中读取数据了。下次查询需要访问这个数据页的时候，将数据也读入内存，然后执行 change buffer 中与这个页有关的操作。

- change buffer 在内存中有拷贝，也会持久化到磁盘

- 将 change buffer 中的数据应用到原数据页的时候，过程称为 merge。除了访问这个数据页会触发merge外，系统有后台线程定期merge。在数据库正常关闭的过程中，也会执行merge 操作。


**什么条件使用 change buffer**

唯一索引的更新(包括插入)更新操作，要验证是否满足唯一性约束，需要将数据读入内存，此时数据也已经存在于内存了，所以唯一索引不会使用 change buffer。

只有普通索引才会使用到 change buffer，即普通索引且内存中不存在对应的数据页。

**change buffer 的使用场景**

change buffer 主要是将更新操作缓存下来，对于写多读少的业务场景，收益较大，如账单、日志类。

**change buffer 和 redo log**

插入下面的语句，假设K1所在的数据页 page1 在内存中，k2 所在数据页 page2 不在。

```
insert into t (id, k) values (id1, k1), (id2, k2)
```

过程如下：

1. Page1 在内存中，直接更新内存
2. Page2 不在内存中，就在内存的 change buffer 区域，记录下 "在page2插入这一行"
3. 将上述两个动作记入 redo log



读取数据过程(page2 数据还没有写入磁盘)：

1. 读 page1 直接从内存返回
2. 读 page2 需要将page2 从磁盘读入内存中，然后应用 change buffer 里的操作日志，生成一个正确的版本返回

对比：**redo log 主要减少的是随机写磁盘的IO消耗，而 change buffer 主要节省的是随机读磁盘的消耗。**



## 用动态的观点看加锁

加锁规则（两个原则，两个优化，一个“bug”）：

- 原则1：加锁的基本单位是next-key lock，next-key-lock 是一个前开后闭的区间
- 原则2：查找过程中访问到的对象才加锁
- 优化1：索引上的等值查询，唯一索引的时候，next-key lock 退化为行锁。
- 优化2：所有上的等值查询，向右遍历的时最后一个值不满足等值查询条件的时候，next-key lock 退化为间隙锁。
- bug：唯一索引上的范围查询，会访问到不满足条件的第一个值。





未完待续...



















































